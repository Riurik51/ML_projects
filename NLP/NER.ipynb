{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XmQb24fvAOwu"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a886166ee634493c91dc05633ba64c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fa28ce061796463c83ed303636bc44d8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e1a2e89fe191445cb86670a7c02f54d4",
              "IPY_MODEL_1dfc786e5f674805a0807c9ca63977d7"
            ]
          }
        },
        "fa28ce061796463c83ed303636bc44d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1a2e89fe191445cb86670a7c02f54d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29f6b5adae4c4683adce9aec9051d1b2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d20c726c641945cb92f3200893823048"
          }
        },
        "1dfc786e5f674805a0807c9ca63977d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_915d319dc42e4d5e84817ed021400c4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 593kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1bbecd8fb28947958c308bb908057485"
          }
        },
        "29f6b5adae4c4683adce9aec9051d1b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d20c726c641945cb92f3200893823048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "915d319dc42e4d5e84817ed021400c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1bbecd8fb28947958c308bb908057485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "hSDMYzIcuaiK",
        "outputId": "6480073b-9b7a-4f6b-f31e-788d45de8535"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload() #upload kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7aaa5bd7-43ec-4575-b5af-e15275a395b3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7aaa5bd7-43ec-4575-b5af-e15275a395b3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"riurik51\",\"key\":\"f0e27f5ac318208f9d9a6e0dfb3c65f6\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLMlczzyvPic",
        "outputId": "453fa9dd-8b29-4f59-904d-1957b27cd9b9"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibe3W9CTvom5",
        "outputId": "564ba671-4739-4c60-a628-30febf5e6ede"
      },
      "source": [
        "!kaggle competitions download -c litbank-ozon-2020"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading train_sents.csv.zip to /content\n",
            "  0% 0.00/387k [00:00<?, ?B/s]\n",
            "100% 387k/387k [00:00<00:00, 51.0MB/s]\n",
            "Downloading test_sents_without_answers.csv to /content\n",
            "  0% 0.00/437k [00:00<?, ?B/s]\n",
            "100% 437k/437k [00:00<00:00, 71.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abapxx5-vuKX",
        "outputId": "98af549a-4329-465a-86c6-f71a5bca5cfa"
      },
      "source": [
        "!unzip '/content/train_sents.csv.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/train_sents.csv.zip\n",
            "  inflating: train_sents.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eogItwb1bJHq"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb0L4Esc0rB2"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEQx6DE1d7oI"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-lOG5t3xKKm"
      },
      "source": [
        "train_list = []\n",
        "with open('train_sents.csv') as file:\n",
        "    file.readline()\n",
        "    cur_sent_list = []\n",
        "    cur_tags_list = []\n",
        "    for line in file:\n",
        "        if line == '\\n':\n",
        "            train_list.append([cur_sent_list, cur_tags_list])\n",
        "            cur_sent_list = []\n",
        "            cur_tags_list = []\n",
        "        else:\n",
        "            if len(line.split(',')) == 2:\n",
        "                cur_list = line[:-1].split(',')\n",
        "                cur_sent_list.append(cur_list[0])\n",
        "                if cur_list[1] == 'O':\n",
        "                    cur_tags_list.append(cur_list[1])\n",
        "                else:\n",
        "                    cur_tags_list.append(cur_list[1])\n",
        "            else:\n",
        "                cur_sent_list.append(',')\n",
        "                cur_tags_list.append('O')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqmYC2QU1Ha2"
      },
      "source": [
        "df = pd.read_csv('train_sents.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEwP-Yl4mGWA"
      },
      "source": [
        "names = np.unique(df['tag'])\n",
        "\n",
        "# names = [\n",
        "#          'O',\n",
        "#          'FAC',\n",
        "#          'GPE',\n",
        "#          'LOC',\n",
        "#          'ORG',\n",
        "#          'PER',\n",
        "#          'VEH'\n",
        "# ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB_EPIvd8INv"
      },
      "source": [
        "id_to_name = {}\n",
        "for i, x in enumerate(names):\n",
        "    id_to_name[i] = x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFSgrcxIArrD"
      },
      "source": [
        "name_to_id = {}\n",
        "for x in id_to_name:\n",
        "    name_to_id[id_to_name[x]] = x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATwnzH1yx0v2"
      },
      "source": [
        "for value in train_list:\n",
        "   value[1] = list(map(lambda x: name_to_id[x], value[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnj4i4RlNU60"
      },
      "source": [
        "from gensim.models import word2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKEghn0-N0nl"
      },
      "source": [
        "train_tokens = []\n",
        "for val in train_list:\n",
        "    train_tokens.append(val[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7PVpZJAWvmP"
      },
      "source": [
        "test_list = []\n",
        "with open('/content/test_sents_without_answers.csv') as file:\n",
        "    file.readline()\n",
        "    cur_sent_list = []\n",
        "    for line in file:\n",
        "        if line == '\\n':\n",
        "            test_list.append(cur_sent_list)\n",
        "            cur_sent_list = []\n",
        "        else:\n",
        "            if len(line.split(',')) == 2:\n",
        "                cur_list = line[:-1].split(',')\n",
        "                cur_sent_list.append(cur_list[1])\n",
        "            else:\n",
        "                cur_sent_list.append(',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmQb24fvAOwu"
      },
      "source": [
        "#BILSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vPNaPW9Ikuk"
      },
      "source": [
        "w2v = word2vec.Word2Vec(train_tokens + test_list,\n",
        "                        workers=4,\n",
        "                        size=300,\n",
        "                        min_count=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuRZsmwCdTzQ"
      },
      "source": [
        "class NER_Train_Dataset(Dataset):\n",
        "    def __init__(self, train_list, w2v_model, max_sentence_lenght, num_features):\n",
        "        #embedding dim = 300\n",
        "        self.w2v_model = w2v_model\n",
        "        self.num_features = num_features\n",
        "        lens_to_sent_dict = {}\n",
        "        for x in train_list:\n",
        "            if len(x[0]) in lens_to_sent_dict.keys():\n",
        "                lens_to_sent_dict[len(x[0])].append(x)\n",
        "            else:\n",
        "                lens_to_sent_dict[len(x[0])] = [x]\n",
        "        self.lens_to_sent_dict = lens_to_sent_dict\n",
        "        self.idxes = list(lens_to_sent_dict.keys())\n",
        "\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.idxes)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        curr_list = self.lens_to_sent_dict[self.idxes[idx]]\n",
        "        curr_labels = []\n",
        "        curr_tokens = []\n",
        "        for x in curr_list:\n",
        "            curr_tokens.append([])\n",
        "            for word in x[0]:\n",
        "                curr_tokens[-1].append(self.w2v_model[word])\n",
        "            curr_labels.append(x[1])\n",
        "        return torch.FloatTensor(curr_tokens), torch.LongTensor(curr_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLN1WHXxbP_O"
      },
      "source": [
        "train_set = NER_Train_Dataset(train_list[:50 * 113], w2v, 307, 300)\n",
        "val_set = NER_Train_Dataset(train_list[50 * 113:], w2v, 307, 300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFwMIsxcBnCM"
      },
      "source": [
        "class My_Loss(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(My_Loss, self).__init__()\n",
        "        self.criterion = nn.CrossEntropyLoss(reduce=False)\n",
        "        self.k = k\n",
        "    \n",
        "    def forward(self, pred, true):\n",
        "        losses = self.criterion(pred.view(-1, pred.shape[2]),\n",
        "                             true.view(-1).to(device)).view(true.shape[0], true.shape[1], -1)\n",
        "        pos_loss = losses[true > 0].sum()\n",
        "        num_pos = (true > 0).sum().cpu().item()\n",
        "        num_neg = num_pos * self.k\n",
        "        if num_neg > len(losses[true == 0].view(-1)):\n",
        "            num_neg = len(losses[true == 0].view(-1))\n",
        "        neg_loss = torch.topk(losses[true == 0].view(-1), num_neg)[0].sum()\n",
        "        if num_pos + num_neg == 0:\n",
        "            return pos_loss + neg_loss\n",
        "        return (pos_loss + neg_loss) / (num_pos + num_neg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNyGZOn3jHVh"
      },
      "source": [
        "class Simple_Bilstm(nn.Module):\n",
        "    def __init__(self, num_features, hidden_size, num_layers, num_entities):\n",
        "        super(Simple_Bilstm, self).__init__()\n",
        "        self.BiLstm = nn.LSTM(num_features, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.Output = nn.Linear(2 * hidden_size, num_entities)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.BiLstm(x)[0]\n",
        "        x = self.Output(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQvGY9nwuVcw"
      },
      "source": [
        "def accuracy(pred, true):\n",
        "    # N x seq x class\n",
        "    # N x seq\n",
        "    preds = torch.argmax(pred, 2) == true\n",
        "    return preds.sum() / (true.shape[0] * true.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pti8k9n0rQO9"
      },
      "source": [
        "def train(train_loader,\n",
        "          model,\n",
        "          criterion,\n",
        "          optimizer,\n",
        "          num_epoch,\n",
        "          val_loader,\n",
        "          gradient_clip):\n",
        "    for epoch in range(1, num_epoch + 1):\n",
        "        train_loss = 0\n",
        "        val_loss = 0\n",
        "        val_acc = 0\n",
        "        for data, true_class in tqdm(train_loader,\n",
        "                        position=0,\n",
        "                        leave=True,\n",
        "                        mininterval=2):\n",
        "            pred = model(data.to(device))\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(pred, true_class.to(device))\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm(model.parameters(), gradient_clip)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, true_class in tqdm(val_loader,\n",
        "                                       position=0,\n",
        "                                       leave=True,\n",
        "                                       mininterval=2):\n",
        "                pred = model(data.to(device))\n",
        "                val_loss += criterion(pred, true_class.to(device))\n",
        "                val_acc += accuracy(pred, true_class.to(device)).item()\n",
        "\n",
        "        print(f'Train Loss on epoch {epoch}: {train_loss / len(train_loader)}')\n",
        "        print(f'Val Loss on epoch {epoch}: {val_loss / len(val_loader)}')\n",
        "        print(f'Val Accuracy: {val_acc / len(val_loader)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN_UZEHUrYJZ"
      },
      "source": [
        "train_set = NER_Train_Dataset(train_list[:50 * 113], w2v, 307, 300)\n",
        "val_set = NER_Train_Dataset(train_list[50 * 113:], w2v, 307, 300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49AZTjlEx1Tr"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58iQgnSzwERF"
      },
      "source": [
        "model = Simple_Bilstm(300, 300, 5, 13).to(device)\n",
        "criterion = My_Loss(1)\n",
        "gradient_clip = 5.0\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0015)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xYZ9CbTswqq",
        "outputId": "ac1a02ce-c86e-4605-ff08-4e31f816364a"
      },
      "source": [
        "train(train_set, model, criterion, optimizer, 5, val_set, gradient_clip)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 119/119 [00:10<00:00, 10.95it/s]\n",
            "100%|██████████| 98/98 [00:02<00:00, 36.85it/s]\n",
            "  0%|          | 0/119 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss on epoch 1: 0.660460274478718\n",
            "Val Loss on epoch 1: 0.6986675262451172\n",
            "Val Accuracy: 0.8516281387027429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 119/119 [00:10<00:00, 11.21it/s]\n",
            "100%|██████████| 98/98 [00:02<00:00, 36.52it/s]\n",
            "  0%|          | 0/119 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss on epoch 2: 0.6006453115915676\n",
            "Val Loss on epoch 2: 0.7267576456069946\n",
            "Val Accuracy: 0.8516281387027429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 119/119 [00:10<00:00, 10.95it/s]\n",
            "100%|██████████| 98/98 [00:02<00:00, 36.29it/s]\n",
            "  0%|          | 0/119 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss on epoch 3: 0.5561891051523873\n",
            "Val Loss on epoch 3: 0.6692062020301819\n",
            "Val Accuracy: 0.8516281387027429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 119/119 [00:10<00:00, 11.10it/s]\n",
            "100%|██████████| 98/98 [00:02<00:00, 36.97it/s]\n",
            "  0%|          | 0/119 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss on epoch 4: 0.529724503157586\n",
            "Val Loss on epoch 4: 0.6473711729049683\n",
            "Val Accuracy: 0.8516281387027429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 119/119 [00:10<00:00, 11.16it/s]\n",
            "100%|██████████| 98/98 [00:02<00:00, 36.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss on epoch 5: 0.517044269411087\n",
            "Val Loss on epoch 5: 0.6338331699371338\n",
            "Val Accuracy: 0.8516281387027429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSsYydwR0GYb"
      },
      "source": [
        "Без CRF не очень - все как 'O'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVmK3kYQABlY"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxcOccKM8H14"
      },
      "source": [
        "Часть кода для предобработки взята из https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2dSTKuktoPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f50dd7e-bcd1-4352-d6ff-b419b5299c03"
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.5MB 11.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 35.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 41.2MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o0QaHiphLTM"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl_x_EF3iVBq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PTS1u6wiES9"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0Dogf1K9Kz6"
      },
      "source": [
        "import transformers\n",
        "from transformers import  BertForTokenClassification, BertTokenizer, AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwLZCp-eizHq"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JGrjVbz9VGv"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "MAX_LEN = 75\n",
        "bs = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "a886166ee634493c91dc05633ba64c3a",
            "fa28ce061796463c83ed303636bc44d8",
            "e1a2e89fe191445cb86670a7c02f54d4",
            "1dfc786e5f674805a0807c9ca63977d7",
            "29f6b5adae4c4683adce9aec9051d1b2",
            "d20c726c641945cb92f3200893823048",
            "915d319dc42e4d5e84817ed021400c4a",
            "1bbecd8fb28947958c308bb908057485"
          ]
        },
        "id": "acbK3nHS9Sdz",
        "outputId": "ce6b82a7-cd14-4f41-9704-d66f346f9841"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a886166ee634493c91dc05633ba64c3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_Mnr_yO5WNa",
        "outputId": "1289ba75-3f46-415b-c969-9d782280f236"
      },
      "source": [
        "len(tokenizer.tokenize('Once upon a midnight dreary, while I pondered, weak and weary, \\Over many a quaint and curious volume of forgotten lore — \\While I nodded, nearly napping, suddenly there came a tapping, \\As of some one gently rapping, rapping at my chamber door. \\'Tis some visitor,\\' I muttered, \\'tapping at my chamber door— \\Only this and nothing more.'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er2-60AT9nR9"
      },
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMoeqzDLAgli"
      },
      "source": [
        "tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in train_list\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DicHxI-bAWNU"
      },
      "source": [
        "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
        "labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q42G_wTkhPsw"
      },
      "source": [
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frhXxwlEhoyQ",
        "outputId": "c0ae7c85-39c7-4e1b-c0f8-2af1555d6d6a"
      },
      "source": [
        "len(id_to_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d26jhFbzhSsz"
      },
      "source": [
        "tags = pad_sequences(labels,\n",
        "                     maxlen=MAX_LEN, value=len(id_to_name), padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JekWe0MKh_Am"
      },
      "source": [
        "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IlLOInXiNt2"
      },
      "source": [
        "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n",
        "                                                            random_state=42, test_size=0.1)\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=42, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QdxTm6Eiit8"
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKPODsc3ipUw"
      },
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMQgq8gmi1RU",
        "outputId": "12c604dc-4b66-483d-a0a5-003e5c36d21c"
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained(\n",
        "    PRE_TRAINED_MODEL_NAME,\n",
        "    num_labels=len(id_to_name) + 1,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V9oC3-DjZbh"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woT1jUhyjjSZ"
      },
      "source": [
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe3CJH2-jnNO"
      },
      "source": [
        "epochs = 3\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtK75e0OmKdy"
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kc9kq_a5zg7"
      },
      "source": [
        "def bert_accuracy(pred, true, pad_lable):\n",
        "    return (torch.argmax(pred, dim = 2) == true)[true != pad_lable].sum() / (true != pad_lable).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW9HKqgQlHUA"
      },
      "source": [
        "def train(train_loader,\n",
        "          model,\n",
        "          optimizer,\n",
        "          num_epoch,\n",
        "          val_loader,\n",
        "          scheduler,\n",
        "          max_grad_norm,\n",
        "          pad_lable):\n",
        "    for epoch in range(1, num_epoch + 1):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        val_loss = 0\n",
        "        val_acc = 0\n",
        "        train_acc = 0\n",
        "        for batch in tqdm(train_loader,\n",
        "                        position=0,\n",
        "                        leave=True,\n",
        "                        mininterval=2):\n",
        "            pred = model(batch[0].to(device), token_type_ids=None,\n",
        "                attention_mask=batch[1].to(device), labels=batch[2].to(device))\n",
        "            optimizer.zero_grad()\n",
        "            loss = pred[0]\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            scheduler.step()\n",
        "            train_acc += bert_accuracy(pred[1], batch[2].to(device), pad_lable).item()\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader,\n",
        "                                       position=0,\n",
        "                                       leave=True,\n",
        "                                       mininterval=2):\n",
        "                pred = model(batch[0].to(device), token_type_ids=None,\n",
        "                            attention_mask=batch[1].to(device), labels=batch[2].to(device))\n",
        "                val_loss += pred[0]\n",
        "                val_acc += bert_accuracy(pred[1], batch[2].to(device), pad_lable).item()\n",
        "\n",
        "        print(f'Train Loss on epoch {epoch}: {train_loss / len(train_loader)}')\n",
        "        print(f'Val Loss on epoch {epoch}: {val_loss / len(val_loader)}')\n",
        "        print(f'Val Accuracy: {val_acc / len(val_loader)}')\n",
        "        print(f'Train Accuracy: {train_acc / len(train_loader)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEtyxrsxkF_f",
        "outputId": "59bf0ebb-9dd2-42b7-f013-df7dae5d8551"
      },
      "source": [
        "train(train_dataloader, model, optimizer, epochs, valid_dataloader, scheduler, max_grad_norm, len(id_to_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 194/194 [01:25<00:00,  2.26it/s]\n",
            "100%|██████████| 22/22 [00:03<00:00,  6.73it/s]\n",
            "  0%|          | 0/194 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss on epoch 1: 0.36427823250594826\n",
            "Val Loss on epoch 1: 0.21760499477386475\n",
            "Val Accuracy: 0.930943405086344\n",
            "Train Accuracy: 0.8966127188549828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 194/194 [01:25<00:00,  2.26it/s]\n",
            "100%|██████████| 22/22 [00:03<00:00,  6.71it/s]\n",
            "  0%|          | 0/194 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss on epoch 2: 0.17400003155482183\n",
            "Val Loss on epoch 2: 0.18087607622146606\n",
            "Val Accuracy: 0.9423060986128721\n",
            "Train Accuracy: 0.9459532047669912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 194/194 [01:25<00:00,  2.27it/s]\n",
            "100%|██████████| 22/22 [00:03<00:00,  6.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss on epoch 3: 0.11862590832194102\n",
            "Val Loss on epoch 3: 0.18809418380260468\n",
            "Val Accuracy: 0.9447241208770059\n",
            "Train Accuracy: 0.9636923477207262\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFKbDZy3ANBu",
        "outputId": "0de8533f-5e14-48e0-e322-40965bfe3549"
      },
      "source": [
        "next(iter(train_dataloader))[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 75])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNqX2A1I8Ptw"
      },
      "source": [
        "test_list = []\n",
        "with open('/content/test_sents_without_answers.csv') as file:\n",
        "    file.readline()\n",
        "    cur_sent_list = []\n",
        "    cur_id_list = []\n",
        "    for line in file:\n",
        "        if line == '\\n':\n",
        "            test_list.append([cur_sent_list, cur_id_list])\n",
        "            cur_sent_list = []\n",
        "            cur_id_list = []\n",
        "        else:\n",
        "            if len(line.split(',')) == 2:\n",
        "                cur_list = line[:-1].split(',')\n",
        "                cur_sent_list.append(cur_list[1])\n",
        "                cur_id_list.append(cur_list[0])\n",
        "            else:\n",
        "                cur_sent_list.append(',')\n",
        "                cur_id_list.append(line.split(',')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_2eE4uYFapW",
        "outputId": "fee0e944-5423-411a-c48f-1c8f02239285"
      },
      "source": [
        "test_list[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['PROLOGUE',\n",
              "  'IT',\n",
              "  'was',\n",
              "  '2',\n",
              "  'p.m.',\n",
              "  'on',\n",
              "  'the',\n",
              "  'afternoon',\n",
              "  'of',\n",
              "  'May',\n",
              "  '7',\n",
              "  ',',\n",
              "  '1915',\n",
              "  '.'],\n",
              " ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e05O5BkK90aq"
      },
      "source": [
        "tokenized_texts_and_ids = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in test_list\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP6fCSCR-S2v"
      },
      "source": [
        "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_ids]\n",
        "ids = [token_label_pair[1] for token_label_pair in tokenized_texts_and_ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc9trEQK920b"
      },
      "source": [
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wboWzeY-gva"
      },
      "source": [
        "test_ids = pad_sequences(ids,\n",
        "                     maxlen=MAX_LEN, value=-1, padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbSk8x0L_nC-"
      },
      "source": [
        "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPtYSOp5-8y9"
      },
      "source": [
        "input_ids = torch.tensor(input_ids).cuda()\n",
        "attention_masks = torch.tensor(attention_masks).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaIuArY-_HIv"
      },
      "source": [
        "with torch.no_grad():\n",
        "    output = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXWumezwICAW",
        "outputId": "aba81478-b3f1-4b88-93d6-827934e3955f"
      },
      "source": [
        "label_indices.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1669, 75)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTWUw1kHIFrl",
        "outputId": "dcc59688-a047-4674-a966-43616d0564e4"
      },
      "source": [
        "test_ids.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1669, 75)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrf4IuxrApmA"
      },
      "source": [
        "answer = pd.DataFrame(np.arange(41365))\n",
        "answer['tag'] = 'O'\n",
        "pred_ind = 0\n",
        "for test_ind_row, answer_row in zip(test_ids, label_indices):\n",
        "    for ind, ans in zip(test_ind_row, answer_row):\n",
        "        if ind > -1 and pred_ind != ind:\n",
        "            answer['tag'][ind] = id_to_name[ans]\n",
        "        pred_ind = ind"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cYcRQUDCGwR"
      },
      "source": [
        "answer.rename(columns={0: 'id'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aNw19vMC-NA"
      },
      "source": [
        "answer.to_csv('answer.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}