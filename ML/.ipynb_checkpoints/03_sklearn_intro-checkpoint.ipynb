{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке `sklearn` реализованы почти все базовые методы машинного обучения. Для них предусмотрены специальные унифированные интерфейсы (и их копируют другие библиотеки). Большинство алгоритмов написаны достаточно эффективно. Кроме того, в `sklearn` содержит дополнительные утилиты, в частности, для предобработки данных и выбора модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных\n",
    "\n",
    "Модуль `sklearn.preprocessing`\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "Далее всюду полагаем, что:\n",
    "1. `X.ndim == 2`;\n",
    "2. `X.shape = (n_objects, n_features)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnTransformerInterface:\n",
    "    def __init__(self, **params):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, **params):\n",
    "        # do some stuff: tune parameters on train\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **params):\n",
    "        # do some stuff: apply transform on test\n",
    "        return X_transformed\n",
    "    \n",
    "    def fit_transform(self, X, **params):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразования масштаба"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MinMaxScaler` приводит значения в столбцах к отрезку `[0,1]` (признаки):\n",
    "\n",
    "```python\n",
    "assert X.ndim == 2\n",
    "\n",
    "X_min = X.min(axis=0)[np.newaxis,:]\n",
    "X_max = X.max(axis=0)[np.newaxis,:]\n",
    "\n",
    "X_transformed = (X - X_min) / (X_max - X_min)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4eb6926dc43d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9872\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(9872)\n",
    "\n",
    "X = np.random.randint(0, 10, size=(5, 10))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaler.fit(X)\n",
    "X_transformed = scaler.transform(X)\n",
    "\n",
    "# same as: X_transformed = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25 , 0.2  ],\n",
       "       [0.   , 0.6  ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.625, 1.   ],\n",
       "       [0.   , 0.   ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed[:, [5, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  7,  9,  0,  1,  2,  2,  7,  4,  1],\n",
       "       [ 0,  0,  0,  0,  5,  0,  3,  2,  1,  3],\n",
       "       [ 8,  8,  9,  2,  7,  8,  9,  0,  3,  0],\n",
       "       [ 4,  5,  6,  8,  3,  5,  7,  6,  0, 10],\n",
       "       [ 7,  6,  3,  2,  5,  0,  3,  6,  6,  0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_copy = X.copy()\n",
    "X_copy[-2, -1] = 10\n",
    "X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25 , 0.2  ],\n",
       "       [0.   , 0.6  ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.625, 2.   ],\n",
       "       [0.   , 0.   ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed = scaler.transform(X_copy)\n",
    "X_transformed[:, [5, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StandardScaler` стандартизирует значения в столбцах (признаки):\n",
    "\n",
    "```python\n",
    "assert X.ndim == 2\n",
    "\n",
    "X_mean = X.mean(axis=0)[np.newaxis,:]\n",
    "X_std  = X.std(axis=0)[np.newaxis,:]\n",
    "\n",
    "X_transformed = (X - X_mean) / X_std\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_transformed = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32274861, -0.4125685 ],\n",
       "       [-0.96824584,  0.61885275],\n",
       "       [ 1.61374306, -0.92827912],\n",
       "       [ 0.64549722,  1.65027399],\n",
       "       [-0.96824584, -0.92827912]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed[:, [5, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight:bold\">Вопрос:</span> а зачем вообще нужны такие `scaler`-ы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Normalizer` нормирует строки (объекты) по заданной норме:\n",
    "\n",
    "```python\n",
    "assert X.ndim == 2\n",
    "\n",
    "# l2-norm\n",
    "X_norm = X / np.power(X, 2).sum(axis=1)\n",
    "\n",
    "# l1-norm\n",
    "X_norm = X / np.abs(X).sum(axis=1)\n",
    "\n",
    "# max-norm\n",
    "X_norm = X / X.max(axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalizer(norm='l2')\n",
    "X_norm = norm.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(X_norm, 2).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy = X.copy()\n",
    "X_copy[1, 2] = 100\n",
    "\n",
    "X_norm = norm.transform(X_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(X_norm, 2).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight:bold\">Вопрос:</span> почему `Normalizer` не нужен этап `fit`, в отличие от `Scaler`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/encoding.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Europe'],\n",
       "       ['Europe'],\n",
       "       ['USA'],\n",
       "       ['Asia'],\n",
       "       ['Europe'],\n",
       "       ['Asia'],\n",
       "       ['Europe'],\n",
       "       ['Europe'],\n",
       "       ['Asia'],\n",
       "       ['Europe']], dtype='<U6')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9826)\n",
    "\n",
    "data = np.random.choice([\"Asia\", \"USA\", \"Europe\"], size=10)\n",
    "data = data.reshape(-1, 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```LabelEncoder``` кодирует категориальные признаки порядковым набором чисел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0, 1, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit_transform(data.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Asia', 'Europe', 'USA'], dtype='<U6')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`OneHotEncoder` для каждого категориального значения создает отдельный столбец."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "encoder.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight:bold\">Вопрос:</span> чем onehot-кодирование лучше label-кодирования? В каких случаях label-кодирование может дать лучший результат?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Понижение размерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9756)\n",
    "\n",
    "X = np.random.random(size=(200, 5))\n",
    "X[:, 3] = np.log(1 + np.abs(X[:, 2])) + np.log(1 + np.abs(X[:, 1]))\n",
    "X[:, 4] = 5 * X[:, 2] - 2 * X[:, 3] + X[:, 1] ** 2\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PCA` – метод главных компонент (principal component analysis). Метод понижения размерности, основанный на `SVD`-разложении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=3)\n",
    "X_transformed = pca.fit_transform(X)\n",
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83406879, 0.09305942, 0.07141035])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985385564104098"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TruncatedSVD` – усечённое сингулярное разложение матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модели\n",
    "\n",
    "Модули для задачи обучения с учителем:\n",
    "* `sklearn.linear_model` – обощенная линенейная модель: `LinearRegression` и `LogisticRegression`;\n",
    "* `sklearn.svm` – машина опорных векторов;\n",
    "* `sklearn.tree` – деревья решений;\n",
    "* `sklearn.neighbors` – метрические алгоритмы классификации и регрессии: `KNN`;\n",
    "* `sklearn.naive_bayes` – наивный Байес;\n",
    "* `sklearn.ensemble` – ансамбли моделей (в основном деревья);\n",
    "\n",
    "и др.\n",
    "\n",
    "Модули для обучения задач без учителя:\n",
    "* `sklearn.mixture` –  EM-алгоритм для случая нормального распределения;\n",
    "* `sklearn.manifold` – понижение размерности для задач визуализация: `TSNE`;\n",
    "* `sklearn.cluster` –  кластеризация: `K-Means`, агломеративная кластеризация, `DBSCAN` и др.\n",
    "* `sklearn.decomposition` – понижение размерности: `PCA`, `TruncatedSVD`;\n",
    "\n",
    "и др."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задач обучения с учителем имеется общий интерфейс, который используют и другие библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class RandomClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_classes=2, seed=8888):\n",
    "        self.n_classes = n_classes\n",
    "        self.seed = seed\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Does absolutely nothing 🤪\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Method returns np.ndarray y:\n",
    "            y.shape == (X.shape[0], n_classes)\n",
    "        \n",
    "        y satisfies:\n",
    "            sum y[i, j] where j in {0..n_classes} = 1 \n",
    "        \"\"\"\n",
    "        \n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        X = np.asarray(X)\n",
    "        y = np.random.rand(X.shape[0], self.n_classes)\n",
    "        y /= np.expand_dims(y.sum(axis=1), axis=1)\n",
    "            \n",
    "        return y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Method returns np.ndarray y:\n",
    "            y.shape == (X.shape[0], )\n",
    "        \"\"\"\n",
    "        return self.predict_proba(X).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Средства оценки и выбора модели\n",
    "\n",
    "Модуль `sklearn.metrics` – метрики (оценка модели).\n",
    "\n",
    "Модуль `sklearn.model_selection` – выбор модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred, **params):\n",
    "    score = 0\n",
    "    # do some stuff\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'calinski_harabaz_score',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'davies_bouldin_score',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'jaccard_similarity_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'median_absolute_error',\n",
       " 'mutual_info_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'scorer',\n",
       " 'silhouette_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def any_in(a, any_):\n",
    "    return any(v in a for v in any_)\n",
    "\n",
    "list(filter(lambda s: any_in(s, {'score', 'error', 'loss'}), dir(sklearn.metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение выборки на обучающую и проверочную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 10), (200,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9845)\n",
    "\n",
    "X = np.random.random(size=(200, 10))\n",
    "y = np.random.randint(0, 2, size=X.shape[0])\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого мы делали так..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 10), (60, 10))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(9852)\n",
    "\n",
    "thrsh = 0.7\n",
    "index = np.random.permutation(X.shape[0])\n",
    "thrsh = int(thrsh * index.shape[0])\n",
    "\n",
    "index_train, index_test = index[:thrsh], index[thrsh:]\n",
    "\n",
    "X_train, X_test = X[index_train], X[index_test]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... а теперь можно делать так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 10), (60, 10))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(X, train_size=0.7, random_state=9852)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перекрестная проверка (кросс-валидация)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/cross_val.png\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5801282051282051,\n",
       " 0.4363327674023769,\n",
       " 0.5833333333333333,\n",
       " 0.43842364532019706]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True, random_state=9657)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for index_train, index_valid in kf.split(X):\n",
    "    X_train, y_train = X[index_train], y[index_train]\n",
    "    X_valid, y_valid = X[index_valid], y[index_valid]\n",
    "    \n",
    "    cls = RandomClassifier(seed=5426)\n",
    "    cls.fit(X_train, y_train)\n",
    "    y_pred = cls.predict(X_valid)\n",
    "    \n",
    "    score = roc_auc_score(y_valid, y_pred)\n",
    "    scores.append(score)\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое можно делать в один вызов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5787037 , 0.46141975, 0.40635452, 0.51170569])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(RandomClassifier(seed=5426), X, y, scoring='roc_auc', cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
